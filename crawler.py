import streamlit as st
import pandas as pd
import requests
import json
import sqlite3
import datetime
import urllib3
from typing import Union, Dict, Any, List 

# é—œé–‰ SSL æ†‘è­‰è­¦å‘Šï¼ˆCWA æ†‘è­‰å•é¡Œçš„å¿…è¦ä¿®æ­£ï¼‰
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- Configuration ---
DATABASE_NAME = "weather_data.db"
API_URL = "https://opendata.cwa.gov.tw/api/v1/rest/datastore/F-C0032-001" 
# ã€å·²æ›´æ–°é‡‘é‘°ã€‘: è«‹ç¢ºèªæ­¤é‡‘é‘° CWA-F1411072-444D-4D41-B919-FA689356B3E7 æœ‰æ•ˆ
DEFAULT_API_KEY = "CWA-F1411072-444D-4D41-B919-FA689356B3E7" 
DEFAULT_LOCATION = 'è‡ºåŒ—å¸‚'

# --- 1. è³‡æ–™åº«é‚è¼¯ (å¾ crawler.py ç¹¼æ‰¿) ---
def init_db():
    """åˆå§‹åŒ– SQLite è³‡æ–™åº«ã€‚"""
    try:
        conn = sqlite3.connect(DATABASE_NAME)
        cursor = conn.cursor()
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS weather_records (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                dataset_id TEXT NOT NULL,
                fetch_timestamp TEXT NOT NULL,
                location_count INTEGER,
                raw_data TEXT NOT NULL
            )
        """)
        conn.commit()
        conn.close()
        # Streamlit æ‡‰ç”¨ä¸­ä¸é©åˆåœ¨æ¯æ¬¡åŸ·è¡Œæ™‚éƒ½è¼¸å‡º printï¼Œæ”¹ç‚º st.info
        # st.info(f"Database '{DATABASE_NAME}' initialized successfully.")
    except sqlite3.Error as e:
        st.error(f"FATAL DB ERROR during initialization: {e}")

def save_to_db(data: Dict[str, Any]) -> str:
    """å°‡æŠ“å–çš„è³‡æ–™å„²å­˜è‡³è³‡æ–™åº«ã€‚"""
    try:
        with sqlite3.connect(DATABASE_NAME) as conn:
            cursor = conn.cursor()
            dataset_id = data.get("records", {}).get("datasetDescription", "unknown_dataset")
            fetch_time = datetime.datetime.now().isoformat()
            location_count = len(data["records"]["location"])
            raw_data_json = json.dumps(data)

            cursor.execute("""
                INSERT INTO weather_records 
                (dataset_id, fetch_timestamp, location_count, raw_data) 
                VALUES (?, ?, ?, ?)
            """, (dataset_id, fetch_time, location_count, raw_data_json))
            conn.commit()
        
        return f"Successfully saved {location_count} records for dataset '{dataset_id}' to SQLite."
    except sqlite3.Error as e:
        return f"Database Error: Failed to save data to SQLite: {e}"

def get_history_from_db(limit: int = 10) -> Union[List[Dict[str, Any]], str]:
    """å¾è³‡æ–™åº«æª¢ç´¢æ­·å²è¨˜éŒ„ã€‚"""
    try:
        with sqlite3.connect(DATABASE_NAME) as conn:
            conn.row_factory = sqlite3.Row 
            cursor = conn.cursor()
            cursor.execute("""
                SELECT id, dataset_id, fetch_timestamp, location_count, raw_data 
                FROM weather_records 
                ORDER BY fetch_timestamp DESC 
                LIMIT ?
            """, (limit,))
            rows = cursor.fetchall()
            
            history_list = [dict(row) for row in rows]
            
            # å°‡ raw_data JSON æ¬„ä½è§£ç¢¼
            for record in history_list:
                try:
                    record['raw_data'] = json.loads(record['raw_data'])
                except json.JSONDecodeError:
                    record['raw_data'] = {"error": "Corrupted JSON data in DB"}

            return history_list
    except sqlite3.Error as e:
        return f"Database Error: Failed to retrieve history from SQLite: {e}"

# --- 2. çˆ¬èŸ²é‚è¼¯ (å¾ crawler.py ç¹¼æ‰¿) ---
def get_weather_data(api_key: str, location: str) -> Union[Dict[str, Any], str]:
    """ç²å– CWA å¤©æ°£è³‡æ–™ï¼ŒåŒ…å« SSL ä¿®æ­£ã€‚"""
    params = {
        'Authorization': api_key,
        'format': 'JSON',
        'locationName': location 
    }

    try:
        # é—œéµä¿®æ­£ï¼šverify=False
        response = requests.get(API_URL, params=params, timeout=15, verify=False) 
        response.raise_for_status() 
        
        data = response.json()
        if 'success' in data and data['success'] == 'false':
            return f"API Error: {data.get('message', 'Unknown API failure')}"

        return data

    except requests.exceptions.HTTPError as errh:
        if response.status_code in [401, 403]:
            return f"Unauthorized or Forbidden: Check your API key ({response.status_code})."
        return f"HTTP Error: {errh}"
    except requests.exceptions.RequestException as err:
        return f"An unexpected request error occurred: {err}"
    except json.JSONDecodeError:
        return "Failed to decode JSON response from the API."

# --- 3. è§£æé‚è¼¯ (å¾ crawler.py ç¹¼æ‰¿) ---
def parse_weather_forecast(data: Dict[str, Any]) -> List[Dict[str, Any]]:
    """è§£æ CWA 36 å°æ™‚é å ±è³‡æ–™ï¼Œæå–é—œéµè³‡è¨Šã€‚"""
    forecasts = []
    try:
        location = data['records']['location'][0]
        location_name = location['locationName']
        weather_elements = location['weatherElement']
        
        element_map = {elem['elementName']: elem['time'] for elem in weather_elements}
        
        if 'Wx' in element_map:
            wx_times = element_map['Wx']
            
            for period in wx_times:
                start_time = period['startTime']
                
                weather_description = period['elementValue'][0]['value']
                
                # æå– PoP, MinT, MaxT (ä½¿ç”¨ next() è™•ç†æ‰¾ä¸åˆ°çš„æƒ…æ³)
                pop_value = next((t['elementValue'][0]['value'] for t in element_map.get('PoP', []) if t['startTime'] == start_time), 'N/A')
                min_t = next((t['elementValue'][0]['value'] for t in element_map.get('MinT', []) if t['startTime'] == start_time), 'N/A')
                max_t = next((t['elementValue'][0]['value'] for t in element_map.get('MaxT', []) if t['startTime'] == start_time), 'N/A')
                
                forecasts.append({
                    'Location': location_name,
                    'Start Time': start_time,
                    'End Time': period['endTime'],
                    'Weather': weather_description,
                    'PoP (%)': pop_value,
                    'Min Temp (Â°C)': min_t,
                    'Max Temp (Â°C)': max_t,
                })

    except Exception as e:
        st.warning(f"è³‡æ–™è§£æç™¼ç”ŸéŒ¯èª¤: {e}")
        return []
        
    return forecasts

# --- 4. Streamlit æ‡‰ç”¨ä»‹é¢ ---
st.set_page_config(page_title="CWA å¤©æ°£è³‡æ–™æŠ“å–èˆ‡åˆ†æ", layout="wide")
st.title("ğŸ‡¹ğŸ‡¼ CWA å¤©æ°£è³‡æ–™å³æ™‚æŠ“å–èˆ‡æ­·å²è¨˜éŒ„")

# ç¢ºä¿è³‡æ–™åº«åœ¨æ‡‰ç”¨ç¨‹å¼å•Ÿå‹•æ™‚åˆå§‹åŒ–
init_db() 

# --- å´é‚Šæ¬„è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ API è¨­å®š")
    api_key_input = st.text_input("API Key (CWA)", value=DEFAULT_API_KEY, type="password")
    location_input = st.text_input("åœ°é»åç¨±", value=DEFAULT_LOCATION)
    
    st.subheader("ğŸ“š æ­·å²è¨˜éŒ„æŸ¥è©¢")
    history_limit = st.slider("é¡¯ç¤ºè¨˜éŒ„ç­†æ•¸", min_value=1, max_value=50, value=5)

# --- ä¸»æ‡‰ç”¨å€å¡Š ---

st.header("å³æ™‚å¤©æ°£é å ±æŠ“å–")
if st.button("ğŸš€ æŠ“å–æœ€æ–° 36 å°æ™‚å¤©æ°£é å ±"):
    # ä½¿ç”¨ Streamlit å…§å»ºçš„ spinner é¡¯ç¤ºè¼‰å…¥ç‹€æ…‹
    with st.spinner(f'æ­£åœ¨æŠ“å– {location_input} çš„è³‡æ–™...'):
        
        # åŸ·è¡ŒæŠ“å–
        weather_data = get_weather_data(api_key_input, location_input)

        if isinstance(weather_data, dict):
            st.success("âœ… è³‡æ–™æŠ“å–æˆåŠŸï¼")
            
            # å„²å­˜è³‡æ–™
            save_msg = save_to_db(weather_data)
            st.info(save_msg)
            
            # è§£æä¸¦é¡¯ç¤ºé å ±
            parsed_forecast = parse_weather_forecast(weather_data)
            
            if parsed_forecast:
                df = pd.DataFrame(parsed_forecast)
                st.subheader(f"æœ€æ–°é å ±ï¼š{location_input} ({len(parsed_forecast)} å€‹æ™‚æ®µ)")
                st.dataframe(df, use_container_width=True)
            else:
                st.warning("è³‡æ–™è§£æå¤±æ•—æˆ–é å ±æ ¼å¼ä¸æ­£ç¢ºã€‚")
        else:
            st.error(f"âŒ è³‡æ–™æŠ“å–å¤±æ•—: {weather_data}")

# --- æ­·å²è³‡æ–™é¡¯ç¤ºå€å¡Š ---
st.divider()
st.header("æ­·å²æŠ“å–è¨˜éŒ„")

history_data = get_history_from_db(history_limit)

if isinstance(history_data, str) and history_data.startswith("Database Error:"):
    st.error(f"âŒ æ­·å²è³‡æ–™æª¢ç´¢å¤±æ•—: {history_data}")
elif history_data:
    st.info(f"é¡¯ç¤ºæœ€è¿‘ {len(history_data)} ç­†è¨˜éŒ„ã€‚")
    
    # å»ºç«‹ä¸€å€‹åŒ…å«é—œéµè³‡è¨Šçš„ DataFrame
    history_df_list = []
    for record in history_data:
        history_df_list.append({
            "ID": record["id"],
            "æŠ“å–æ™‚é–“": record["fetch_timestamp"],
            "è³‡æ–™é›†æè¿°": record["raw_data"]["records"]["datasetDescription"],
            "åœ°é»æ•¸": record["location_count"],
        })
    
    st.dataframe(pd.DataFrame(history_df_list), use_container_width=True)
    
    # é¸é …ï¼šå±•é–‹æŸ¥çœ‹åŸå§‹ JSON
    if st.checkbox("å±•é–‹åŸå§‹ JSON è³‡æ–™"):
        selected_id = st.selectbox("é¸æ“‡è¦æŸ¥çœ‹çš„è¨˜éŒ„ ID", [r["id"] for r in history_data])
        raw_record = next(r for r in history_data if r["id"] == selected_id)
        st.json(raw_record["raw_data"])

else:
    st.info("è³‡æ–™åº«ä¸­å°šç„¡æ­·å²è¨˜éŒ„ã€‚")
